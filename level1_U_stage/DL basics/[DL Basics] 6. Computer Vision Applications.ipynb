{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4c92a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6272fb",
   "metadata": {},
   "source": [
    "많은 용어들을 정확히 정의하고 이해해야 타 연구자들과 커뮤니케이션에서 문제가 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52397538",
   "metadata": {},
   "source": [
    "## 6. Computer Vision Applications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa881fa2",
   "metadata": {},
   "source": [
    "### 6-1.Semantic Segmentation\n",
    "\n",
    "* (dense / per pixel) classification 라고도 불림\n",
    "\n",
    "픽셀별로 이미지를 분류하는 것\n",
    "\n",
    "* 자율주행과 같은 곳에 주로 쓰인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf55451",
   "metadata": {},
   "source": [
    "### 6-2. Fully Convolutional Network\n",
    "Fully Convolutional Network의 목적은 Dense layer를 없애고 Convolutional layer로 변경하기 위함이지만, 기존의 Dnse layer와 파라미터 숫자는 똑같다.\n",
    "\n",
    "<img src=\"https://github.com/dongseoklee1541/boostcamp_AI_Tech_3/blob/main/images/131027.png?raw=ture\" width=\"500\"> \n",
    "\n",
    "\n",
    "#### 특징\n",
    "* input의 크기(shape)와 관계 없이 작동할 수 있다. input의 크기의 변화에 따라서 컨볼루션 연산 결과의 크기(special demension)만 달라지고 작동할 수 있다. \n",
    "    * 기존의 Dense layer는 정해진 크기만 입력 가능\n",
    "* 출력의 결과는 단순 분류만 하는 것이 아닌 히트맵 또는 Semantic Segmentation이 가능해보이는 가능성을 보여준다.\n",
    "    * 다만 FCN의 결과로 크기가 달라져 input의 크기로 늘려주는 방법이 필요하다. -> Deconvolution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab696c3",
   "metadata": {},
   "source": [
    "#### 6-2-1. Deconvolution\n",
    "\n",
    "<img src=\"https://github.com/dongseoklee1541/boostcamp_AI_Tech_3/blob/main/images/132907.png?raw=ture\" width=\"500\"> \n",
    "\n",
    "Conv transpose, 컨볼루션의 역 연산\n",
    "* 엄밀히 말하면 역연산은 존재할 수 없음, 기존의 픽셀 값들이 합쳐져서 원본으로 복원하는 것은 불가능 다만 **네트워크 구성이 편해지므로 역연산으로 생각하자.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db78679c",
   "metadata": {},
   "source": [
    "## 6-2. Detection\n",
    "\n",
    "이미지안에서 물체가 어디있는지 bounding box로 그려주는 것\n",
    "\n",
    "#### 6-2-1. R-CNN\n",
    "\n",
    "<img src=\"https://github.com/dongseoklee1541/boostcamp_AI_Tech_3/blob/main/images/133824.png?raw=ture\" width=\"500\"> \n",
    "\n",
    "이미지를 받아 2천개의 region을 뽑고, 똑같은 크기로 맞춘뒤 AlexNet(feature extraction역할)과 Linear SVM을 이용해 분류를 한다.\n",
    "\n",
    "* 2천개의 region : Selective search를 통해 여기 있을것 같다고 생각하는 후보군을 각각 다른 크기의 bounding box로 뽑는다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9850645",
   "metadata": {},
   "source": [
    "#### 6-2-2. SPPNet\n",
    "\n",
    "<img src=\"https://github.com/dongseoklee1541/boostcamp_AI_Tech_3/blob/main/images/134540.png?raw=ture\" width=\"500\"> \n",
    "\n",
    "R-CNN의 단점이였던 2천번을 돌아야 했던 Conv 연산을 이미지 전체에서 **한번만** 돌린 후 bounding box에 해당하는 값들만 가져온다.\n",
    "\n",
    "* SPP(spatial pyramid pooling) : feature map을 잘 조리해서 하나의 fixed map으로 바꿔줌\n",
    "* 다만 이 모델도 SPP를 거치는 과정이 필요해 시간이 오래걸린다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9088358c",
   "metadata": {},
   "source": [
    "#### 6-2-3. Fast R-CNN\n",
    "\n",
    "<img src=\"https://github.com/dongseoklee1541/boostcamp_AI_Tech_3/blob/main/images/134959.png?raw=ture\" width=\"500\"> \n",
    "\n",
    "SPPNet의 컨셉인 이미지 전체에 한번만 Conv연산을 돌린 후 2천개의 각각의 region에 대해 ROI pooling으로 정보를 뽑아내고, bounding box의 위치 조정과 분류를 진행한다.\n",
    "\n",
    "* ROI feature vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ca3e46",
   "metadata": {},
   "source": [
    "#### 6-2-4. Faster R-CNN\n",
    "\n",
    "<img src=\"https://github.com/dongseoklee1541/boostcamp_AI_Tech_3/blob/main/images/135826.png?raw=ture\" width=\"500\"> \n",
    "\n",
    "Faster R-CNN = **Region Proposal Network** + Fast R-CNN\n",
    "\n",
    "#### Region Proposal Network(RPN)\n",
    "\n",
    "<img src=\"https://github.com/dongseoklee1541/boostcamp_AI_Tech_3/blob/main/images/140234.png?raw=ture\" width=\"500\"> \n",
    "\n",
    "해당하는 공간에 물체가 있을지 없을지를 찾아주기만 하는 역할, 이 물체가 무엇인지는 뒤의 네트워크가 해줄 것\n",
    "\n",
    "* anchor boxes : 미리 크기를 지정한 bounding box\n",
    "\n",
    "<img src=\"https://github.com/dongseoklee1541/boostcamp_AI_Tech_3/blob/main/images/141150.png?raw=ture\" width=\"500\"> \n",
    "\n",
    "* 4 : bounding box의 높이 너비와 x,y좌표\n",
    "* 2 : 해당 bounding box가 쓸모가 있는지 없는지(confidence) 판단"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9acf79",
   "metadata": {},
   "source": [
    "#### 6-2-5. YOLO\n",
    "\n",
    "<img src=\"https://github.com/dongseoklee1541/boostcamp_AI_Tech_3/blob/main/images/143123.png?raw=ture\" width=\"500\"> \n",
    "\n",
    "Faster-RCNN 과 달리 bounding box와 분류를 한번에 하여 속도가 빠르다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a73baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2f2aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
